{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65f40bf0-52c1-4d3a-ac34-419ea041f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import json\n",
    "\n",
    "data_dir = Path(r\"C:\\Users\\alexa\\Desktop\\Untitled Folder\")  # Pfad ggf. anpassen\n",
    "files = sorted(data_dir.glob(\"*.json\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb02390-de7e-4f33-acf7-fb0e3ce90404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "\n",
    "batch_size = 20  # Anzahl Dateien pro Batch, kann je nach RAM angepasst werden\n",
    "dfs_batch = []\n",
    "dfs_final = []\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    try:\n",
    "        dfs_batch.append(pd.read_json(f, lines=True))\n",
    "    except ValueError:\n",
    "        obj = json.loads(f.read_text(encoding=\"utf-8\"))\n",
    "        if isinstance(obj, list):\n",
    "            dfs_batch.append(pd.DataFrame(obj))\n",
    "        elif isinstance(obj, dict):\n",
    "            dfs_batch.append(pd.json_normalize(obj))\n",
    "        else:\n",
    "            raise ValueError(f\"Unbekanntes JSON-Format in {f.name}\")\n",
    "\n",
    "    # Sobald batch_size erreicht ist oder letzte Datei, zusammenfügen und aufsammeln\n",
    "    if (i + 1) % batch_size == 0 or (i + 1) == len(files):\n",
    "        temp_df = pd.concat(dfs_batch, ignore_index=True)\n",
    "        dfs_final.append(temp_df)\n",
    "        dfs_batch.clear()\n",
    "        gc.collect()  # Speicher freigeben\n",
    "\n",
    "# Endgültig alle Batches zusammenfügen\n",
    "df = pd.concat(dfs_final, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a45ca-6b40-4ac1-a8b5-20ae48e49daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielhafte Umbenennung auf erwartete Spalten\n",
    "rename_map = {\n",
    "    \"duration_ms\": \"exec_time_ms\",\n",
    "    \"duration\": \"exec_time_ms\",\n",
    "    \"latency\": \"latency_ms\",\n",
    "    \"cpu_time_ms\": \"cpu_ms\",\n",
    "    \"memory_gb_s\": \"mem_mb_s\",  # ggf. skaliert konvertieren\n",
    "    \"transfer_mb\": \"data_transfer_mb\"\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "\n",
    "# Metadaten aus Dateinamen extrahieren (optional, je nach Namensschema)\n",
    "def extract_meta(path: Path):\n",
    "    # Beispiel: aws_eu_110_cold_results_256.json\n",
    "    parts = path.stem.split(\"_\")\n",
    "    meta = {}\n",
    "    if len(parts) >= 6:\n",
    "        meta[\"provider\"] = parts\n",
    "        meta[\"scenario\"] = parts[12]\n",
    "        meta[\"load\"] = int(parts[13]) if parts[13].isdigit() else parts[13]\n",
    "        meta[\"start_type\"] = parts[14]\n",
    "        meta[\"platform\"] = \"lambda\"  # Beispiel; ggf. aus Inhalt ableiten\n",
    "        meta[\"settings\"] = {\"memory\": parts[15]}\n",
    "    return meta\n",
    "\n",
    "meta_rows = []\n",
    "for f in files:\n",
    "    meta_rows.append(extract_meta(f))\n",
    "import pandas as pd\n",
    "meta_df = pd.DataFrame(meta_rows)\n",
    "df[[c for c in meta_df.columns if c not in df.columns]] = meta_df[[c for c in meta_df.columns if c not in df.columns]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f98d89-4c30-40f8-bc76-60dfd382a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, json\n",
    "\n",
    "data_dir = Path(r\"C:\\Users\\alexa\\Desktop\\Untitled Folder\")\n",
    "print(\"Suche in:\", data_dir.resolve())\n",
    "\n",
    "# 1) Dateien sammeln: .json und .jsonl, notfalls rekursiv\n",
    "files = sorted(list(data_dir.glob(\"*.json\"))) + sorted(list(data_dir.glob(\"*.jsonl\")))\n",
    "if not files:\n",
    "    files = sorted(list(data_dir.rglob(\"*.json\"))) + sorted(list(data_dir.rglob(\"*.jsonl\")))\n",
    "print(f\"{len(files)} Dateien gefunden\")\n",
    "print([f.name for f in files[:5]])  # Stichprobe\n",
    "\n",
    "def load_one(f: Path) -> pd.DataFrame:\n",
    "    # Versuch A: JSON-Lines\n",
    "    try:\n",
    "        dfA = pd.read_json(f, lines=True)\n",
    "        if not dfA.empty:\n",
    "            return dfA\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # Versuch B: Normales JSON\n",
    "    obj = json.loads(f.read_text(encoding=\"utf-8\"))\n",
    "    if isinstance(obj, list):\n",
    "        return pd.DataFrame(obj)\n",
    "    if isinstance(obj, dict):\n",
    "        # Heuristik: erst Liste von Records in einem Key suchen\n",
    "        for k, v in obj.items():\n",
    "            if isinstance(v, list) and v and isinstance(v, dict):\n",
    "                return pd.json_normalize(v)\n",
    "        # Sonst Top-Level-Dict flatten\n",
    "        return pd.json_normalize(obj)\n",
    "    # Fallback: leere Tabelle\n",
    "    return pd.DataFrame()\n",
    "\n",
    "parts = []\n",
    "for f in files:\n",
    "    dfi = load_one(f)\n",
    "    print(f\"{f.name}: {dfi.shape}\")\n",
    "    parts.append(dfi)\n",
    "\n",
    "df = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "print(\"Gesamt:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68c2ba-a5dd-4591-abc3-5e3bb2c382ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = {\"provider\",\"platform\",\"scenario\",\"load\",\"start_type\",\"exec_time_ms\",\"latency_ms\",\n",
    "            \"cpu_ms\",\"mem_mb_s\",\"data_transfer_mb\",\"cost\",\"settings\"}\n",
    "missing = expected - set(df.columns)\n",
    "if missing:\n",
    "    # Beispiel: fehlende Spalten mit NaN auffüllen (besser: korrekt mappen/ableiten)\n",
    "    for col in missing:\n",
    "        df[col] = pd.NA\n",
    "# harte Prüfung\n",
    "missing = expected - set(df.columns)\n",
    "assert not missing, f\"Fehlende Spalten: {missing}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c758d-3e48-4bba-b7f5-0ee5ee10dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"exec_time_ms\",\"latency_ms\",\"cost\"]\n",
    "\n",
    "def iqr_filter(group, cols):\n",
    "    for c in cols:\n",
    "        q1 = group[c].quantile(0.25)\n",
    "        q3 = group[c].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5*iqr\n",
    "        upper = q3 + 1.5*iqr\n",
    "        group = group[(group[c] >= lower) & (group[c] <= upper)]\n",
    "    return group\n",
    "\n",
    "df_clean = (df\n",
    "    .groupby([\"provider\",\"platform\",\"scenario\",\"load\",\"start_type\"], group_keys=False)\n",
    "    .apply(lambda g: iqr_filter(g, metrics)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d770ded-7bca-4ec4-b9c5-6d07d8ca41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.catplot(\n",
    "    data=df_clean, kind=\"box\",\n",
    "    x=\"provider\", y=\"latency_ms\",\n",
    "    col=\"load\", row=\"start_type\",\n",
    "    sharey=False, height=3, aspect=1.2\n",
    ")\n",
    "g.set_xticklabels(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bd460-c5c9-4f53-9331-dea75581b1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122bd73-3687-4ce6-b801-010a3af60214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
